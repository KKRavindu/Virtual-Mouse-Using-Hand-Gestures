# ğŸ–±ï¸ Virtual Mouse Using Hand Gestures

This project implements a **Virtual Mouse** that can be controlled entirely using hand gestures detected through a webcam. By leveraging **computer vision** and **machine learning models** for hand landmark detection, the system replaces traditional mouse input devices and enables gesture-based interaction with the computer.

---

## ğŸ“– Description
The virtual mouse uses **OpenCV** and **MediaPipe** to detect and track hand landmarks in real time. Recognized gestures are mapped to mouse events using **PyAutoGUI**, enabling actions such as cursor movement, left/right clicks, scrolling, and drag-and-drop.  
An additional **eye-hand fusion module** allows for enhanced precision and smoother control.  

This approach demonstrates the potential of **vision-based human-computer interaction (HCI)**, offering touch-free and intuitive control mechanisms for accessibility and innovative applications.

---

## ğŸš€ Features
- ğŸ‘† Cursor control with index finger  
- ğŸ‘‰ğŸ‘† Left click (index + middle finger pinch)  
- ğŸ‘‰ğŸ’ Right click (middle + ring finger pinch)  
- ğŸ‘ğŸ‘† Scroll up/down (thumb + index distance)  
- ğŸ‘ğŸ–• Drag & Drop (thumb + middle finger)  
- ğŸ‘†ğŸ–•ğŸ’ Precision mode (stable small movements)  
- ğŸ‘ï¸ Eye-hand fusion for better accuracy  

---

## ğŸ› ï¸ Tech Stack
- Python 3  
- OpenCV  
- MediaPipe  
- PyAutoGUI  
- NumPy  

---

## â–¶ï¸ Usage
Run the scripts inside the **src/** folder:

```bash
python src/camera_test.py       # Test camera
python src/cusor_controller.py  # Main cursor control
python src/eye_hand_fussion.py  # Eye + hand fusion mode
python src/guestues.py          # Gesture recognition test

Press ESC to exit. Keep your hand inside the camera view.
